\chapter{Implementation}

This project is realized in Go. Go is an open-source programming language that makes it easy to build simple, reliable, and efficient software \cite{go:web}. Go brings many concurrency features like lightweight multiplexed threads, typed conduits named channels which allow goroutines to synchronize without explicit locks or condition variables \cite{go:tour}. Go's sync package provides Mutexes, Conds, Once, and more. It also comes with cross-platform support and rich cross compilers.

The source code will be structured into the following packages: 
\begin{itemize}
  \item Broker contains everything for the broker service.
  
  \item Cmd contains all program entry points and main functions for the different opp\_edge tools.
  
  \item Gconfig contains configuration definitions and default values used by various packages. It parses command-line arguments to change the following values dynamically: broker address and port number, the Stargate port number, worker name, and how many jobs start. It also provides the OS-specific paths to the cache and configuration directory.
  
    \item Omnetpp contains command-line wrappers for OMNeT++. This package can clean and compile the simulation, extract simulation configurations and run numbers. It also executes simulation runs.
    
    \item Proto contains the Protobuf and gRPC service definition files for the Broker, Storage and the Provider. It also includes the generated Go code from the definition files.

    \item Provider contains the gRPC Provider service implementation, a resource allocator, connection listeners, and the implementation for running the simulation, compressing results.

    \item Simple contains generic helper functions.
    
    \item Stargate establishes connections over the local network, peer-to-peer, or a relay server. It also handles the NAT-traversal process.
    
    \item Mimic contains tools that turn UDP connections into QUIC connections. It also includes utils that use QUIC connections to mimic TCP connections. These tools are needed to establish gRPC connections over UDP and QUIC.
    
    \item Stargrpc is the "gRPC over stargate" package. It employs Stargate and Mimic to create gRPC connections and servers.
    
    \item Storage transfers files between two devices. It holds helper functionality to simplify the transfer of large files.
\end{itemize}

\section{Simple}
The simple package contains generic helper functions used across many packages.

The FakeCopy function will create symlinks in the target directory, which point to all files in the source directory. The function will recreate every directory in the source in the target. Think of this as a copy function for directories that creates a symlink instead of an actual copy for files.

Simple also contains functionality to handle the extraction and compression of files. TarGzFiles tars and compresses files. Symlinks are handled correctly, an implementation for other special files like fifos is currently missing. TarGz tars and compresses all files in a directory. Files can be excluded by defining regexes that will be matched against file paths. ExtractTarGz extracts a tar gzip archive to the desired destination. The input is the compressed archive as a byte array.

Simple provides the functionality to identify files that changed in a directory. ListDirChecksum returns a list of all files in the given directory with its blake2b checksum. The blake2b is used because it is faster than MD5, SHA-1, SHA-2, and SHA-3. DirDiff compares the checksums of two file lists with one another. The files that do not match will be returned. The FilesChangeDetector is a struct that detects and bundles modified files that were changed. To do this, it creates a list of files and their checksums at the beginning. The ZipChanges function is called after changes in the directory occur. The function creates a new file list with checksums and compares these to the original list. Only the changed files will then be compressed and returned.

\section{Stargate}
The Stargate module establishes direct UDP and TCP connections between providers and consumers over the local network, peer-to-peer, or a relay server. Before the connection process can start both peers need to know where the server for the exchange of connection information is located. SetConfig sets the address and port number of this server.

The Stargate server starts TCP and UDP listeners on the same port number. The UDP listener is used to broker peer-to-peer connections. The TCP listener is used to broker relay connections.

To connect two peers it is necessary that both have the same dial address in the form of a string. This string is typically the provider-id. DialLocal broadcasts the dialAddr to the local network. It returns a TCP address on which to connect to the peer. BroadcastTCP is the counterpart to this process, it listens for multicast broadcasts and responds with a port on which to connect if the dialAddr matches.

DialP2PUDP returns a UDP peer-to-peer connection. This function uses the in "\ref{Connect-over-Peer-to-Peer} Design: Connect over Peer-to-Peer" described NAT traversal technique. The returned connection is already established and tested.

DialRelayTCP establishes a TCP relay connection over the stargate server as described in "\ref{Connect-over-a-Relay-Server} Design: Connect over a Relay Server".

\section{Mimic}
Commonly gRPC uses dial calls to connect to a server and listeners to host a server over TCP. The mimic package contains helper functionalities to establish gRPC connections over established UDP and TCP connections. This package is called "mimic" because it mimics functionality that is required to use gRPC.

The peer-to-peer connections in this work are established over UDP. UDP is not supported by gRPC currently, because it lacks TCP features like reliability and ordered data delivery. To fix this this work proposes the use of QUIC, which will use the underlying UDP connection. See Figure \ref{fig:Communication-Layer} for an overview of this.

\begin{figure}
  \centering
  \includesvg[width=400pt]{images/Communication Layer.svg}
  \caption{Communication Layers}
  \label{fig:Communication-Layer}
\end{figure}

When the link is established over the local network or the relay server, the stargate package returns an already established TCP connection. The function TCPConnToListener wraps this TCP connection into a TCP listener. With the Accept call, the already established connection will be returned. After that, the Accept call will be blocked and not return any new connections. This listener can be passed to a gRPC server to "listen" for incoming calls. The gRPC server calls the "Accept" call to connect to clients.

The function NewQUICListener creates a QUIC connection listener from an established UDP connection. The listener implements the Go net.Listener interface, the standard interface for TCP listeners that can be passed to a gRPC server.

The function NewDialAdapter creates a new dialer that can be passed to the gRPC dial call. This dialer will use the UDP connection to communicate with the server. The UDP connection will be enhanced by turning it into a QUIC connection.

\section{Stargrpc}
The stargrpc package contains functionalities that establish a gRPC connection by using the stargate package. It incorporates gRPC server functionalities for three connection ways as well as corresponding dial calls.

ServeLocal takes as an input a stargate dial address and a gRPC server. It creates a TCP listener and serves the input server. The 'stargate.BroadcastTCP' function will be used to respond with the port number of the server to broadcasts. DialLocal creates a gRPC client connection over the local network. It uses the 'stargate.DialLocal' command to retrieve a TCP address in the local network. On that address, it connects with the standard 'grpc.Dial' call. 

ServeP2P establishes a peer-to-peer connection over stargate to serve the server. As an input, it takes a stargate dial address and a gRPC server. It uses the 'stargate.DialP2PUDP' call to connect to a client over peer-to-peer. The resulting UDP connection will be transformed to a 'net.Listener' by calling the 'mimic.NewQUICListener' function. Afterward, the serve function of the server will be called with the listener. DialP2P creates a gRPC client connection over peer-to-peer. It uses the 'stargate.DialP2PUDP' command to establish a UDP connection to the server. The gRPC dial call then uses the 'mimic.NewDialAdapter' function to start a gRPC connection from the UDP connection.

ServeRelay establishes a relay connection over stargate to serve the server. As an input, it takes a Stargate dial address and a gRPC server. The 'stargate.DialRelayTCP' call connects to a client over the relay server. The resulting TCP connection will be transformed to a 'net.Listener' by calling the 'mimic.TCPConnToListener' function. Afterward, the serve function of the server is called with the listener. DialRelay creates a gRPC client connection over the stargate relay server to the dialed address. The 'stargate.DialRelayTCP' command establishes a TCP connection to the server. The gRPC dial call then employs the 'grpc.WithContextDialer' option to utilize the established connection.

The code (\ref{code:DialP2P}) example presents how the stargrpc package interacts with the stargate and mimic package. The example shows the peer-to-peer connection, but works similarly for the local and relay connections.

\newpage
\begin{lstlisting}[caption={Example of how the stargrpc package interacts with the stargate and mimic package}, label={code:DialP2P}, language=Go]
func DialP2P(
    ctx context.Context,
    addr stargate.DialAddr) (cc *grpc.ClientConn, err error) {

  log.Printf("DialP2P: %v", addr)

  ctx, cln := context.WithTimeout(ctx, time.Second*5)
  defer cln()

  gate, raddr, err := stargate.DialP2PUDP(ctx, addr)
  if err != nil {
     return
  }

  adapter := mimic.NewDialAdapter(gate)

  return grpc.DialContext(
     ctx,
     raddr.String(),
     grpc.WithInsecure(),
     grpc.WithBlock(),
     grpc.WithContextDialer(adapter),
  )
}
\end{lstlisting}

\section{Broker}
The broker implements two gRPC Functions. The 'Register' function receives a gRPC stream of Pings as input. A ping can either be cast to a 'ProviderInfo' or as a 'Utilization' status. The ProviderInfo contains the provider-id, the OS and architecture, and the number of CPUs. The Utilization contains the temporary CPU usage, the used memory, and a timestamp. The provider sends a ProviderInfo as the first message. Afterward, the utilization will be sent periodically. With the connection of the stream, the provider will be added to the provider list. When the stream collapses the provider will be removed from the provider list. Every change in the provider list triggers a roll out to each consumer. Consumers get these events by calling the brokers 'Providers' gRPC function. The 'Providers' stream function dispatches the provider list to the consumer. The broker starts a Stargate server to broker peer-to-peer connections and to provide a relay server.

\section{Storage}
Storage package transfers files between two devices. It contains the gRPC storage implementation and helper functions that simplify the transfer of large files for both clients and server. The storage server stores files in the omnetpp cache directory. The storage directory contains subdirectories which represent buckets. Buckets are directories that are used to bundle files that are related to each other, like simulation results.

The storage server has a gRPC implementation for storing files named Push. gRPC messages have a size limit hence large files need to be transferred in a stream of data chunks. The stream's metadata includes the file name and designated bucket. When the transfer is completed a storage reference is returned to the client. Storage references are Protobuf messages, which consist of the filename and the bucket.

Pull is the counterpart to Push, it implements the gRPC server function for retrieving files. It receives a storage reference and then streams the file in chunks to the client.

Delete is the gRPC server implementation for deleting files. It takes as an input a storage reference and deletes the according file in the bucket. Drop is the gRPC server implementation for deleting buckets. 

PushFile and PullFile are used to bypass the gRPC push and pull process for efficiency reasons and can therefore only be used locally on the server.

The storage packages also provide client functionalities to simplify the interaction with the storage gRPC server. The storage client offers functions that handle the streamed upload and download procedure. The function Upload uploads a file to the storage server and returns a storage reference. The function Download downloads a file from the storage server and returns it bytes.

\section{Consumer}
The consumer package contains every functionality to offload the simulation to providers. The function 'OffloadSimulation' starts the offloading process to the providers. The function takes as an input parameter the Omnetpp configuration. The offload configuration has additional fields that specify which simulation configuration should be run. If files should be excluded from the distribution process, for example the .git directory.

First of all a unique simulation-id will be generated. This id will be used to identify the simulation. In the next step a connection to the broker will be established. The simulation source will be compressed by using 'simple.TarGz'.

After that a new Go structure will be created that holds all information that will be used and modified during the simulation execution. The struct contains the following data:
\begin{itemize}
    \item The simulation-id.
    \item The Go context that will be used, during the whole simulation and execution process, to enforce timeouts.
    \item The simulation configuration contains all OMNeT++ related information.
    \item A 'sync.WaitGroup' to ensure that all tasks are completed before the consumer exits.
    \item A 'taskQueue' that contains all simulation runs. The taskQueue contains simulation-runs and is synchronized and can be used by various agents concurrently.
    \item A map with mutexes for each architecture to ensure that the simulation will be compiled only once.
    \item A map with the simulation exeturables for each architecture.
    \item The compressed simulation source.
\end{itemize}

After the simulation struct is initiated the broker is contacted to get provider list events. With the first connection an initial list will be sent. The consumer calls the gRPC function 'Provider' at the broker to establish a stream. 'ProviderList' will be received every time the list changes.

After the 'ProviderList' was received the connection, deployment, and execution phases can be started for each provider. This will happen concurrently to ensure maximal performance by preventing the mutual blocking of steps.

The consumer can connect to the provider locally, peer-to-peer or over a relay server. The 'pconnect' function will be used to establish a direct gRPC connection to the provider. The function will use three subroutines that are called in the flowing order:
\begin{enumerate}
    \item 'stargrpc.DialLocal' to connect over the local network.
    \item 'stargrpc.DialP2P' to connect peer-to-peer.
    \item 'stargrpc.DialRelay' to connect over the relay server.
\end{enumerate}

After the gRPC connection was successfully established a new 'providerConnection' struct will be created. This structure contains the gRPC clients for the 'provider' and 'storage' services. 

The provider will be prepared to execute the simulation by calling the 'providerConnection' 'deploy' function. This function will upload the simulation and prepare it for execution on the provider.

The simulation source is uploaded and extracted by calling 'extract'. This function uses the 'storage.Client' to upload a file. It calls the gRPC function 'provider.Extract' to extract the uploaded archive.

It will create a new session, check if the source code needs to be uploaded, and check if the simulation executable needs to be uploaded or compiled. It calls 'setupExecutable' to either compile the simulation and download it to the consumer or upload and extract the simulation executable to the provider. It does this by creating a mutex for each architecture, which will be stored in the 'simulation.archLock'. This mutex ensures that only one thread can enter the compile and upload part of the source code. There it checks if 'simulation.binaries' contains the compressed executable bytes for its architecture and OS.
\begin{itemize}
    \item If the map entry is empty the executable is compiled and downloaded. Afterwards it will fill the empty spot in the map with the executable binaries.
    \item If the map entry is not empty it will upload the executable and extracts on the provider.
\end{itemize}

The next step is to initiate the taskQueue. This will be done only once by using the Go 'sync.Once' functionality. The first provider that is prepared to execute the simulation, calls the 'collectTasks' function and adds the results to the 'simulation.taskQueue'. 'collectTasks' creates a list with simulation runs for all specified configs. It calls the gRPC function 'ListRunNums' on the provider to retrieve this information.

The next step is to call the 'execute' function. Know starts the results downloader, handels allocations, and executes simulation-runs.

First it creates a download Go channel, which queues the result-storage-references. It then starts the 'providerConnection.resultsDownloader' to download and extract the results to the local simulation directory. The function 'downloader' downloads results from the download queue. It extracts them with 'simple.ExtractTarGz' to the local simulation source directory. Afterwards it deletes the results from the provider to free up space. If the download fails, the task is rescheduled by adding it to the 'tasksQueue'.

The 'provider.Allocate' gRPC function is called, with the simulation-id in its context metadata, to create a stream. This stream is used to send allocation requests and free operations. An infinite loop is entered that does the following things:
\begin{enumerate}
    \item Request an allocation slot and wait until one is assigned.
    \item It pops a task from the queue and executes it on the provider by calling the provider's gRPC function 'Run'. The function returns a storage reference to the results on the provider. Afterwards it returns the allocationed slot. If the execution was a success it adds the results-reference to the download queue. If the execution fails, the task is rescheduled by adding it back to the tasksQueue.
    \item If the tasks queue is empty the allocated slot is returned. Afterwards the task queue's 'linger' function is called. The linger function waits until either the queues 'close' function is called or a new element is added to the queue. If a new element is added to the queue, the loop continues. If the queue is closed the loop exits and terminates the connection to the provider. This process is necessary to ensure that overallocated resources are returned and that rescheduled tasks can be processed with all available resources.
\end{enumerate}

The consumer exits with a success message after all tasks have been executed successfully.

\section{Omnetpp}
The omnetpp package contains a wrapper for running and compiling OMNeT++ simulations. A project can be initialized by calling the 'New' function with a configuration. The configuration contains all the in "Prepare for the Distribution" mentioned information and a path to the simulation root directory.

Before the simulation executable can be used it needs to be compiled. The simulation is built in two ways. If the configuration contains a build script it calls the script to compile the simulation. Otherwise, the OMNeT++ tool opp\_makemake is used to create a Makefile. Afterwards the simulation is compiled. The packages can also clean the simulation by calling "make clean".

The simulation command has to be called the right way and with the right parameters to work. The required parameters are the NED (-n) and INI files (-f) for the simulation. This information is extracted from the configuration. If the simulation is a library the OMNeT++ command opp\_run is used with the simulation library path as an additional parameter.

The Omnetpp package extracts Information about the simulation. The function QConfigs returns all simulation-configurations from the OMNeT++ project. The function QRunNumbers returns all simulations-run-numbers for the given configuration name. Both functions call the simulation executable. The extracted information is applied to run the simulation-runs.

The function Run performs simulation-runs with the given configuration and run-number. It adds the configuration as the "-c" argument and the run number as the "-r" argument to the simulation command and executes it.

\section{Provider}
Providers and consumers communicate over gRPC services. All gRPC functions provided by the provider are directly called by the consumer. When the provider launches, a new gRPC server is created. The server registers the provider gRPC service and the storage gRPC service (described in "Implementation: Storage"). The server is passed to the Stargrpc server functions together with the provider-id as a dial address. The stargrpc functions create the needed listeners and handle the connection process to the clients automatically. After the provider gRPC server starts the broker is connected to propagate the new provider as described in "Implementation: Broker". 

The struct that is passed to the gRPC server, implements the provider gRPC services described in the Protobuf files and contains the following fields:
\begin{itemize}
    \item providerId: The unique provider id.
    \item store: The storage server for the provider.
    \item slots: A Go channel for resource management.
    \item sessions: A map with sessions for each simulation.
    \item executionTimes: A map with execution times for each simulation. This will be used to decide which simulation will be prioritised.
    \item mu: A mutex to prevent simultaneous editing of values.
    \item allocRecvs: A map with channels to assign allocations to simulations.
    \item newRecv: A Go 'sync.Cond' to wait and broadcast changes in allocRecvs.
\end{itemize}

The provider tries to recover sessions at launch. During this process it checks for expired simulations and cleans them up. GetSession is the gRPC function to create and get a session on the provider. It extracts the deadline from the incoming Go context and ensures that the simulation data will be deleted. The session stores the simulation configuration that is required to use the Omnetpp package. SetSession updated the given session. This is used by the consumer to store if the simulation was uploaded and if the executable is ready.

The consumer uploads the simulation source and if available the simulation executable to the provider. Afterwards, the gRPC function Extract extracts the given storage-reference to the given simulation directory. It uses  'store.PullFile' to fetch the file and 'simple.ExtractTarGz' to extract the file.

Compile is the gRPC function to compile a given simulation. It operates the Omnetpp packages to build the executable and employs the 'simple.FilesChangeDetector' to compress only the executables and libraries. It utilizes 'store.PushFile' to save the binary to storage and to make it available to download. Following that it creates a storage reference that can be returned to the consumer.

ListRunNums is the gRPC function that returns a list of simulation-run-numbers for the given simulation. It uses the Omnetpp packages function 'QRunNumbers' to extract the necessary information.

Run is the gRPC function that executes a given simulation-run. First it creates a 'simple.FakeCopy' of the simulation directory to circumvent concurrency issues described in "Design: Execute the Simulation". Each simulation-run is executed in a separate new directory. The Omnetpp's 'Run' function executes the simulation-run and writes the results to the directory. The 'simple.FilesChangeDetector' detects changes from before and after the simulation-run finishes. Next it compresses only the results to an archive. The archive is pushed to the storage server by calling the PushFile function at the storage server. The generated storage-reference is then returned to the consumer. The time is tracked during the entire process to update the execution duration for the simulation.

Allocate is the gRPC function which handles allocation requests from the consumers. First it extracts the simulation-id from context metadata to identify the simulation. Next it creates a new Go-channel that is used for internal communication to signal allocations to the consumer. This channel is added to the 'prov.allocRecvs', which also triggers an 'newRecv' broadcast event. With each message from the allocation channel a new allocation is sent to the consumer. With each free message from the consumer a slot is fed back to the allocation process by adding a 1 to 'prov.slots'. The function keeps track of assigned slots and feeds them back when the connection collapses. When the stream collapses the allocation channel will be removed from the 'prov.allocRecvs' map.

When a provider initiates the function StartAllocator is called. This function starts the allocation process of slots to consumers. Slots are CPU cores that can be allocated and the number of slots is defined by the number of jobs. Consumers are identified over the simulation-id. The 'prov.slots' buffered Go-channel is initiated and fed with the number of jobs that the provider is allowed to run in parallel. This Go-channel ensures concurrency across multiple resource requesters and safeguards that only the available number of slots are assigned. Whenever a slot is assigned it will be removed from the buffered channel. When a slot is freed a new value is added to the channel.

To assign slots to consumers a loop reads from the slot Go-channel. If the channel is empty the for loop will wait until free slots are available. Inside the loop's body the free slot is assigned to a consumer. 'prov.allocRecvs' map consists of simulation-ids as key values and Go-channels which propagate allocations to the consumer. If the map is empty the 'newRecv' Go-cond is used to wait for the next 'newRecv' broadcast event, which indicates that a new consumer has joined and requests resources. Afterwards the simulation-id with the lowest execution time is chosen to get the free slot. The simulation-id will be used to extract the event channel from the 'prov.allocRecvs' map.

The described allocation and process is decentral and doesn't require a central node like the broker to handle the assignment of resources.

\section{Cmd}
The cmd packages contain the main functions for each tool in the opp\_edge tool box. These are the entry points for the generated command line tools.

\begin{itemize}
    \item opp\_edge\_config: The configuration tool helps to configure default ports and addresses. It creates a default configuration JSON in the omnetpp-edge configuration directory. All tools source this file and use these values as default configuration. It can also show you where data is stored.
    \item opp\_edge\_broker: This command for starting a broker. It sources the default configuration and parses command line arguments for the broker. It will call 'broker.Start' to start the broker.
    \item opp\_edge\_worker: This tool starts a new provider. It sources the default configuration and parses command line arguments for the provider. This calls 'provider.Start' with the configuration.
    \item opp\_edge\_run: This command distributes and runs the simulation remotely. It sources the default configuration and parses command line arguments for the consumer. This starts 'consumer.OffloadSimulation' with the configuration and the right paths.
\end{itemize}

\section{Docker Image}
One result of this work is a Docker image that incorporates all tools to distribute and run the simulation. Docker containers harness a heterogeneous resource pool by providing the same virtual environment and OMNeT++ version on each device. The Docker containers work under Windows, Linux, and macOS the same way. All essential opp\_edge tools described in "Implementation: Cmd" are bundled together with an OMNeT++ environment into a Docker image. Docker images can be conveniently deployed, used, and deleted by users and providers.

The creation of Docker images is also prudent for security and safety reasons. Docker containers run isolated from the OS. Alien code that the consumer executes can not access files of the host system. The host system is also in the position to curb resource usage by the container and the simulations. Runtime options can be set for containers, for example, how much CPU and memory the provider is allowed to seize \cite{docker:resource_constraints}.